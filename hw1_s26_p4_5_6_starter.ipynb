{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Homework 1: Neural Networks from Scratch (Problems 4, 5, 6)\n",
        "\n",
        "**CS-GY 6953 Deep Learning | Spring 2026**\n",
        "\n",
        "--- \n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook contains the starter code for Problems 4, 5, and 6 of Homework 1. \n",
        "\n",
        "**Objectives:**\n",
        "1.  **Problem 4 (15 pts):** Train an MLP on the BloodMNIST medical dataset and perform detailed error analysis.\n",
        "2.  **Problem 5 (15 pts):** Investigate the impact of weight initialization on training dynamics and activation statistics.\n",
        "3.  **Problem 6 (25 pts):** Build a small modular neural network library (`mytorch`) from scratch using NumPy and train it on MNIST.\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "1.  **Complete the code**: Fill in all `TODO` blocks in this notebook and in the `mytorch/` Python files.\n",
        "2.  **Run all cells**: Ensure all outputs, plots, and analyses are visible.\n",
        "3.  **Export/Zip**: Zip this notebook and the `mytorch/` folder together.\n",
        "\n",
        "## Academic Integrity\n",
        "\n",
        "You may discuss concepts with classmates, but all code and written analysis must be your own. Your experimental results (accuracies, confusion matrices, plots) \n",
        "should reflect your actual training runs. Do not fabricate or copy results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "## Setup\n",
        "\n",
        "First, we install the necessary packages. We will use `medmnist` for Problem 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting medmnist\n",
            "  Using cached medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy (from medmnist)\n",
            "  Downloading numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
            "Collecting pandas (from medmnist)\n",
            "  Downloading pandas-3.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
            "Collecting scikit-learn (from medmnist)\n",
            "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
            "Collecting scikit-image (from medmnist)\n",
            "  Downloading scikit_image-0.26.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from medmnist) (4.67.1)\n",
            "Collecting Pillow (from medmnist)\n",
            "  Downloading pillow-12.1.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
            "Collecting fire (from medmnist)\n",
            "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch (from medmnist)\n",
            "  Downloading torch-2.10.0-2-cp313-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting torchvision (from medmnist)\n",
            "  Downloading torchvision-0.25.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.4 kB)\n",
            "Collecting termcolor (from fire->medmnist)\n",
            "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Collecting scipy>=1.11.4 (from scikit-image->medmnist)\n",
            "  Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting networkx>=3.0 (from scikit-image->medmnist)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->medmnist)\n",
            "  Using cached imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tifffile>=2022.8.12 (from scikit-image->medmnist)\n",
            "  Using cached tifffile-2026.2.16-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: packaging>=21 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-image->medmnist) (25.0)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image->medmnist)\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting joblib>=1.3.0 (from scikit-learn->medmnist)\n",
            "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn->medmnist)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from torch->medmnist)\n",
            "  Using cached filelock-3.24.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch->medmnist) (80.9.0)\n",
            "Collecting sympy>=1.13.3 (from torch->medmnist)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jinja2 (from torch->medmnist)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->medmnist)\n",
            "  Using cached fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->medmnist)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->medmnist)\n",
            "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
            "Using cached medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Downloading numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-3.0.1-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.1.1-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.26.0-cp313-cp313-macosx_11_0_arm64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached imageio-2.37.2-py3-none-any.whl (317 kB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tifffile-2026.2.16-py3-none-any.whl (233 kB)\n",
            "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading torch-2.10.0-2-cp313-none-macosx_11_0_arm64.whl (79.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached filelock-3.24.2-py3-none-any.whl (24 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
            "Downloading torchvision-0.25.0-cp313-cp313-macosx_12_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, termcolor, sympy, Pillow, numpy, networkx, MarkupSafe, lazy-loader, joblib, fsspec, filelock, tifffile, scipy, pandas, jinja2, imageio, fire, torch, scikit-learn, scikit-image, torchvision, medmnist\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [medmnist]/23\u001b[0m [torchvision]]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 Pillow-12.1.1 filelock-3.24.2 fire-0.7.1 fsspec-2026.2.0 imageio-2.37.2 jinja2-3.1.6 joblib-1.5.3 lazy-loader-0.4 medmnist-3.0.2 mpmath-1.3.0 networkx-3.6.1 numpy-2.4.2 pandas-3.0.1 scikit-image-0.26.0 scikit-learn-1.8.0 scipy-1.17.0 sympy-1.14.0 termcolor-3.3.0 threadpoolctl-3.6.0 tifffile-2026.2.16 torch-2.10.0 torchvision-0.25.0\n",
            "Requirement already satisfied: numpy in /Users/mudrex/miniconda3/lib/python3.13/site-packages (2.4.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (52 kB)\n",
            "Requirement already satisfied: torch in /Users/mudrex/miniconda3/lib/python3.13/site-packages (2.10.0)\n",
            "Requirement already satisfied: torchvision in /Users/mudrex/miniconda3/lib/python3.13/site-packages (0.25.0)\n",
            "Requirement already satisfied: scikit-learn in /Users/mudrex/miniconda3/lib/python3.13/site-packages (1.8.0)\n",
            "Requirement already satisfied: medmnist in /Users/mudrex/miniconda3/lib/python3.13/site-packages (3.0.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (114 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from matplotlib) (12.1.1)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Using cached pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from torch) (2026.2.0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-learn) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pandas in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from medmnist) (3.0.1)\n",
            "Requirement already satisfied: scikit-image in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from medmnist) (0.26.0)\n",
            "Requirement already satisfied: tqdm in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: fire in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from medmnist) (0.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from fire->medmnist) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-image->medmnist) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-image->medmnist) (2026.2.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /Users/mudrex/miniconda3/lib/python3.13/site-packages (from scikit-image->medmnist) (0.4)\n",
            "Downloading matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
            "Using cached pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
            "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install numpy matplotlib torch torchvision scikit-learn medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import math\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Setup\n",
        "\n",
        "**BloodMNIST**: This dataset will be automatically downloaded by the `medmnist` library when you run the code in Problem 4.\n",
        "\n",
        "**MNIST**: This dataset (used in Problems 5 and 6) will be downloaded to the `./data` directory by `torchvision` in the cell below. \n",
        "Please ensure you have an internet connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download MNIST data (used in Problems 5 and 6)\n",
        "import os\n",
        "\n",
        "# Create data directory\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "\n",
        "print(\"Downloading MNIST...\")\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "print(\"MNIST Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "# Problem 4: Blood Cell Classification with MLPs (15 points)\n",
        "\n",
        "In this problem, you will train a multi-layer perceptron (MLP) to classify microscopy images of blood cells using the **BloodMNIST** dataset.\n",
        "\n",
        "### Q4.1: Data Loading and Exploration (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load BloodMNIST dataset\n",
        "current_data_flag = 'bloodmnist'\n",
        "info = INFO[current_data_flag]\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "class_labels = info['label']\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Define transforms (convert to tensor and normalize)\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load train, validation, and test sets\n",
        "# download=True ensures it is downloaded if not present\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
        "val_dataset = DataClass(split='val', transform=data_transform, download=True)\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=True)\n",
        "\n",
        "# TODO: Report number of samples\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display a grid of 16 random training images (2 per class)\n",
        "# Iterate through the dataset or loader to collect 2 examples per class\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "# ... implementation here ...\n",
        "plt.suptitle(\"BloodMNIST Examples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot the class distribution (bar chart) for the training set\n",
        "# Count occurrences of each class index in train_dataset.labels\n",
        "\n",
        "# ... implementation here ...\n",
        "plt.title(\"Class Distribution (Training Set)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Is the dataset balanced? \n",
        "\n",
        "*TODO: Write your answer here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q4.2: Build and Train an MLP (5 points)\n",
        "\n",
        "Architecture:\n",
        "*   Input: 2352 (flattened 28x28x3)\n",
        "*   Hidden 1: 256 (ReLU)\n",
        "*   Hidden 2: 128 (ReLU)\n",
        "*   Output: 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BloodMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BloodMLP, self).__init__()\n",
        "        # TODO: Define layers\n",
        "        # self.flatten = ...\n",
        "        # self.fc1 = ...\n",
        "        # self.relu = ...\n",
        "        # self.fc2 = ...\n",
        "        # self.fc3 = ...\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Initialize model, optimizer (Adam, lr=1e-3), and loss function (CrossEntropy)\n",
        "model = BloodMLP().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Training Loop\n",
        "num_epochs = 30\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.squeeze().long() # MedMNIST labels are (N, 1)\n",
        "        \n",
        "        # Zero gradients, forward, backward, optimize\n",
        "        # ...\n",
        "        pass\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.squeeze().long()\n",
        "            # ...\n",
        "            pass\n",
        "    \n",
        "    # Print stats\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {running_loss:.4f} Acc: {correct/total:.4f} | Val Loss: {val_loss:.4f} Acc: {val_correct/val_total:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot Training Loss vs Validation Loss\n",
        "# TODO: Plot Training Acc vs Validation Acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q4.3: Evaluation and Analysis (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Evaluate on Test Set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        \n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "# 1. Accuracy\n",
        "# ...\n",
        "\n",
        "# 2. Confusion Matrix\n",
        "# cm = confusion_matrix(all_labels, all_preds)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels.values())\n",
        "# disp.plot(xticks_rotation='vertical')\n",
        "\n",
        "# 3. Classification Report\n",
        "# print(classification_report(...))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Identify 2 most confused pairs\n",
        "# TODO: Find class with lowest recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Display 5 misclassified examples of the lowest-recall class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q4.4: Prediction Confidence Analysis (3 points)\n",
        "\n",
        "Categorize predictions into:\n",
        "*   Confident & Correct (> 0.9)\n",
        "*   Confident & Incorrect (> 0.9)\n",
        "*   Uncertain & Correct (< 0.6)\n",
        "*   Uncertain & Incorrect (< 0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Find and display 2 examples from each quadrant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis:** What visual characteristics distinguish the \"Incorrect but Confident\" examples? Why might the model be overconfident?\n",
        "\n",
        "*TODO: Write your analysis here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "# Problem 5: Weight Initialization and Training Dynamics (15 points)\n",
        "\n",
        "### Q5.1: Implement Initialization Schemes (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_weights(shape, method):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        shape: tuple of (fan_in, fan_out)\n",
        "        method: 'zero', 'small_random', 'xavier', 'he'\n",
        "    Returns:\n",
        "        torch.Tensor of initialized weights\n",
        "    \"\"\"\n",
        "\n",
        "    if len(shape) != 2:\n",
        "        raise ValueError(\"Shape must be a tuple of (fan_in, fan_out)\")\n",
        "\n",
        "    fan_in, fan_out = shape\n",
        "\n",
        "\n",
        "    if method == 'zero':\n",
        "        return torch.zeros(shape)\n",
        "    elif method == 'small_random':\n",
        "        return torch.randn(shape) * 0.01\n",
        "    \n",
        "    elif method == 'xavier':\n",
        "        sigma = math.sqrt(2 / (fan_in + fan_out))\n",
        "        return torch.randn(shape) * sigma\n",
        "    elif method == 'he':\n",
        "        sigma = math.sqrt(2 / fan_in)\n",
        "        return torch.randn(shape) * sigma\n",
        "    else:\n",
        "        raise ValueError(\"Unknown method\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "## tetsing the initialize_weights function\n",
        "print(initialize_weights((10, 10), 'zero'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.9100e-03, -7.9642e-04,  1.3200e-02, -1.5197e-02, -1.2531e-02,\n",
            "         -2.0160e-03, -1.9768e-02,  9.2746e-03,  7.8943e-03,  7.8247e-03],\n",
            "        [-6.4659e-04, -2.2984e-06,  5.6931e-03,  7.4762e-03,  2.1337e-02,\n",
            "          5.0145e-03,  2.9843e-03,  1.3448e-02,  1.4614e-02,  1.0566e-02],\n",
            "        [-5.4614e-03, -2.1778e-03, -2.8094e-03, -3.6046e-03, -3.5718e-03,\n",
            "         -1.1568e-02, -1.7660e-02, -2.5380e-02, -3.3437e-04, -1.7017e-02],\n",
            "        [ 5.8634e-03, -1.7527e-02, -8.9146e-03,  5.2475e-03,  3.5178e-03,\n",
            "          2.4913e-03,  4.2356e-04,  8.9666e-03, -2.3369e-03,  6.0499e-04],\n",
            "        [-1.8495e-03, -1.0381e-02, -1.0130e-03, -9.2718e-03,  7.3442e-03,\n",
            "          3.0971e-04, -5.8653e-03, -3.1545e-03,  2.0147e-03,  3.8398e-03],\n",
            "        [ 1.2310e-02,  1.2287e-02, -1.5806e-03,  6.9485e-03, -1.2785e-02,\n",
            "         -1.2692e-02,  3.2581e-03, -1.4584e-02,  1.8989e-02, -4.0566e-04],\n",
            "        [ 6.4671e-03, -2.0813e-02, -9.3036e-03, -1.3950e-02, -4.1754e-03,\n",
            "          1.1060e-02,  2.5285e-03, -1.0754e-03,  3.0078e-04,  1.7702e-02],\n",
            "        [-9.5189e-03,  3.9345e-03,  9.6260e-03, -1.1049e-02, -7.9095e-03,\n",
            "         -2.1609e-03,  8.5740e-03,  1.1460e-02, -1.1312e-03,  1.4093e-02],\n",
            "        [-1.8900e-02,  1.9432e-03,  1.6020e-02, -1.0372e-02, -7.0210e-03,\n",
            "         -6.7328e-03,  2.0705e-03, -2.6125e-03,  1.6910e-02,  7.4263e-03],\n",
            "        [ 3.0812e-03,  2.0517e-02, -9.7677e-03, -4.4397e-03,  7.3737e-03,\n",
            "         -1.3395e-03, -1.9454e-03, -1.1237e-02,  2.5675e-03, -5.7640e-03]])\n"
          ]
        }
      ],
      "source": [
        "print(initialize_weights((10, 10), 'small_random'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4920,  0.2822,  0.2231,  0.4482, -0.0932, -0.0885,  0.3427,  0.0547,\n",
            "          0.5285, -0.4683],\n",
            "        [-0.3549,  0.1330, -0.1451, -0.2936, -0.0543, -0.2171, -0.0080, -0.2694,\n",
            "         -0.6162, -0.4822],\n",
            "        [ 0.0088,  0.0288,  0.2125,  0.3115,  0.8013, -0.0971,  0.0028, -0.4918,\n",
            "          0.0746, -0.1412],\n",
            "        [-0.3725,  0.4467, -0.2295, -0.3645,  0.3404, -0.7741,  0.2426, -0.2964,\n",
            "         -0.7370, -0.2469],\n",
            "        [ 0.2965, -0.0794,  0.3166, -0.2754,  0.3863, -0.0992, -0.2288, -0.1147,\n",
            "          0.1247,  0.0518],\n",
            "        [ 0.3398,  0.2646,  0.0075, -0.4808,  0.1674, -0.1236, -0.0277, -0.0490,\n",
            "          0.3827, -0.6771],\n",
            "        [-0.1074,  0.0023, -0.0165,  0.3692,  0.2881, -0.2104, -0.4110, -0.1313,\n",
            "         -0.1634, -0.2176],\n",
            "        [ 0.1504, -0.4527,  0.1174,  0.1120,  0.0286,  0.4277, -0.3585, -0.0447,\n",
            "         -0.2042,  0.1297],\n",
            "        [-0.0035,  0.5740,  0.1918,  0.1886,  0.9113, -0.3691,  0.6139, -0.3680,\n",
            "         -0.5049,  0.0263],\n",
            "        [-0.2916, -0.1174, -0.3072,  0.0483,  0.2293, -0.4394,  0.3755,  0.0087,\n",
            "          0.6328, -0.0394]])\n"
          ]
        }
      ],
      "source": [
        "print(initialize_weights((10, 10), 'xavier'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3253, -0.5671, -0.9269, -0.9499, -0.1901, -1.0219,  0.2642,  0.1398,\n",
            "          0.4514,  0.4669],\n",
            "        [ 0.1332,  0.3748,  0.1029, -0.2585, -0.0113, -0.5375, -0.7209, -0.2325,\n",
            "         -0.9325, -0.3825],\n",
            "        [-0.4918,  0.2770, -0.0820,  0.1640, -0.2923,  0.6540,  0.0538,  0.3360,\n",
            "         -0.2617, -0.5410],\n",
            "        [ 0.1404, -0.1184,  0.0156, -0.1205, -0.0925,  0.2000, -0.1265,  0.2396,\n",
            "         -0.1304, -0.4289],\n",
            "        [ 0.9489,  0.1869,  0.1995, -0.0119,  0.2940,  0.2972, -0.4809,  0.0787,\n",
            "          0.6541, -0.8177],\n",
            "        [-0.0634, -0.1091,  0.7641, -0.7038, -0.2024,  0.5256, -0.6555, -0.0281,\n",
            "         -1.1301,  0.2135],\n",
            "        [ 0.3244, -0.7162, -0.2752,  1.0036, -0.4838, -0.0892,  0.7555, -0.2816,\n",
            "         -0.4836, -0.1881],\n",
            "        [-0.6948,  0.4869, -0.5555, -0.1494, -0.7034,  1.2568,  0.4129, -0.2170,\n",
            "         -0.2476, -0.3390],\n",
            "        [-0.0479, -0.4891, -0.5604,  0.4277, -0.5706,  0.9905, -0.2680, -0.1472,\n",
            "         -0.7930, -0.4431],\n",
            "        [ 0.2839,  0.4579,  0.2425,  0.0438, -0.0645, -0.2370,  1.0912, -0.8555,\n",
            "          0.1390, -0.6602]])\n"
          ]
        }
      ],
      "source": [
        "print(initialize_weights((10, 10), 'he'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q5.2: Activation Statistics Before Training (5 points)\n",
        "\n",
        "Architecture: 784 -> 256 -> 256 -> 256 -> 256 -> 256 -> 10\n",
        "Activations: Tanh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Define a custom MLP class that lets you inspect forward passes\n",
        "class InitMLP(nn.Module):\n",
        "    def __init__(self, init_method, activation='tanh'):\n",
        "        super().__init__()\n",
        "        # ...\n",
        "\n",
        "# TODO: Collect stats (mean/std) for each layer across the 4 init methods\n",
        "# Loop through init_methods = ['zero', 'small_random', 'xavier', 'he']\n",
        "#   Instantiate model\n",
        "#   Pass one batch of MNIST data\n",
        "#   Record layer outputs (hooks or manual forward)\n",
        "#   Note: Use the MNIST data downloaded in the 'Data Setup' section: \n",
        "#         loader = DataLoader(mnist_train, batch_size=256, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Plot Mean Activation vs Depth (subplot 1)\n",
        "# TODO: Plot Std Activation vs Depth (subplot 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis:** Which methods show vanishing/exploding gradients?\n",
        "\n",
        "*TODO: Write your analysis here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q5.3: Training Dynamics Comparison (4 points)\n",
        "\n",
        "Train 4 networks (one per init) for 10 epochs on MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Training loop for the 4 models\n",
        "# Plot all 4 training loss curves\n",
        "# Report final test accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q5.4: ReLU Activation Experiment (3 points)\n",
        "\n",
        "Repeat Q5.2 and Q5.3 with **ReLU** instead of Tanh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Activation statistics with ReLU\n",
        "# TODO: Training comparison with ReLU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis:** Compare Tanh vs ReLU dynamics and best initialization methods.\n",
        "\n",
        "*TODO: Write your analysis here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "# Problem 6: Building a Neural Network Library (25 points)\n",
        "\n",
        "You will implement `mytorch` in the provided auxiliary files and then use it here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add current directory to path so we can import mytorch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "import mytorch.nn as nn\n",
        "import mytorch.utils as utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q6.1 - Q6.5: Implementation\n",
        "\n",
        "Please implement the classes in:\n",
        "1.  `mytorch/nn/modules/linear.py`\n",
        "2.  `mytorch/nn/modules/activation.py`\n",
        "3.  `mytorch/nn/modules/loss.py`\n",
        "4.  `mytorch/nn/sequential.py`\n",
        "5.  `mytorch/nn/optim.py`\n",
        "\n",
        "*(Editor's note: You should edit these files directly.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q6.6: Gradient Checking (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mytorch.utils import gradient_check\n",
        "\n",
        "# Create a small dummy network for checking\n",
        "input_size = 5\n",
        "hidden_size = 10\n",
        "output_size = 3\n",
        "batch_size = 4\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, output_size)\n",
        ")\n",
        "\n",
        "loss_fn = nn.SoftmaxCrossEntropy()\n",
        "\n",
        "# Random data\n",
        "x_dummy = np.random.randn(batch_size, input_size)\n",
        "y_dummy = np.eye(output_size)[np.random.choice(output_size, batch_size)]\n",
        "\n",
        "# Check gradients\n",
        "try:\n",
        "    error = gradient_check(model, loss_fn, x_dummy, y_dummy)\n",
        "    print(f\"Gradient check Max Relative Error: {error:.2e}\")\n",
        "    if error < 1e-5:\n",
        "        print(\"Gradient check PASSED!\")\n",
        "    else:\n",
        "        print(\"Gradient check FAILED!\")\n",
        "except NotImplementedError:\n",
        "    print(\"Gradient check not implemented yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q6.7: Train and Evaluate on MNIST (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Train on MNIST using mytorch\n",
        "# 1. Load MNIST (flattened to 784)\n",
        "#    Note: Use the MNIST data downloaded in the 'Data Setup' section.\n",
        "#    You can access it via torchvision or just load the tensors if already loaded.\n",
        "#    X_train = mnist_train.data.float().view(-1, 784) / 255.0\n",
        "#    y_train = mnist_train.targets\n",
        "\n",
        "# 2. Create model: 784 -> 128 (ReLU) -> 64 (ReLU) -> 10\n",
        "# 3. Optimizer: SGD(lr=0.1)\n",
        "# 4. Loss: SoftmaxCrossEntropy\n",
        "# 5. Train for 3 epochs\n",
        "\n",
        "# Plot loss\n",
        "# Report test accuracy\n",
        "# Display 10 random test predictions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
