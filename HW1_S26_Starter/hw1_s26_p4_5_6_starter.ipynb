{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Homework 1: Neural Networks from Scratch (Problems 4, 5, 6)\n",
                "\n",
                "**CS-GY 6953 Deep Learning | Spring 2026**\n",
                "\n",
                "--- \n",
                "\n",
                "## Overview\n",
                "\n",
                "This notebook contains the starter code for Problems 4, 5, and 6 of Homework 1. \n",
                "\n",
                "**Objectives:**\n",
                "1.  **Problem 4 (15 pts):** Train an MLP on the BloodMNIST medical dataset and perform detailed error analysis.\n",
                "2.  **Problem 5 (15 pts):** Investigate the impact of weight initialization on training dynamics and activation statistics.\n",
                "3.  **Problem 6 (25 pts):** Build a small modular neural network library (`mytorch`) from scratch using NumPy and train it on MNIST.\n",
                "\n",
                "## Submission Instructions\n",
                "\n",
                "1.  **Complete the code**: Fill in all `TODO` blocks in this notebook and in the `mytorch/` Python files.\n",
                "2.  **Run all cells**: Ensure all outputs, plots, and analyses are visible.\n",
                "3.  **Export/Zip**: Zip this notebook and the `mytorch/` folder together.\n",
                "\n",
                "## Academic Integrity\n",
                "\n",
                "You may discuss concepts with classmates, but all code and written analysis must be your own. Your experimental results (accuracies, confusion matrices, plots) \n",
                "should reflect your actual training runs. Do not fabricate or copy results.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "## Setup\n",
                "\n",
                "First, we install the necessary packages. We will use `medmnist` for Problem 4."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install medmnist"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "import medmnist\n",
                "from medmnist import INFO, Evaluator\n",
                "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "def set_seed(seed=42):\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "set_seed(42)\n",
                "\n",
                "# Check device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Setup\n",
                "\n",
                "**BloodMNIST**: This dataset will be automatically downloaded by the `medmnist` library when you run the code in Problem 4.\n",
                "\n",
                "**MNIST**: This dataset (used in Problems 5 and 6) will be downloaded to the `./data` directory by `torchvision` in the cell below. \n",
                "Please ensure you have an internet connection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download MNIST data (used in Problems 5 and 6)\n",
                "import os\n",
                "\n",
                "# Create data directory\n",
                "os.makedirs('./data', exist_ok=True)\n",
                "\n",
                "print(\"Downloading MNIST...\")\n",
                "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
                "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
                "print(\"MNIST Ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "# Problem 4: Blood Cell Classification with MLPs (15 points)\n",
                "\n",
                "In this problem, you will train a multi-layer perceptron (MLP) to classify microscopy images of blood cells using the **BloodMNIST** dataset.\n",
                "\n",
                "### Q4.1: Data Loading and Exploration (2 points)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Load BloodMNIST dataset\n",
                "current_data_flag = 'bloodmnist'\n",
                "info = INFO[current_data_flag]\n",
                "n_channels = info['n_channels']\n",
                "n_classes = len(info['label'])\n",
                "class_labels = info['label']\n",
                "\n",
                "DataClass = getattr(medmnist, info['python_class'])\n",
                "\n",
                "# Define transforms (convert to tensor and normalize)\n",
                "data_transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[.5], std=[.5])\n",
                "])\n",
                "\n",
                "# Load train, validation, and test sets\n",
                "# download=True ensures it is downloaded if not present\n",
                "train_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
                "val_dataset = DataClass(split='val', transform=data_transform, download=True)\n",
                "test_dataset = DataClass(split='test', transform=data_transform, download=True)\n",
                "\n",
                "# TODO: Report number of samples\n",
                "print(f\"Train samples: {len(train_dataset)}\")\n",
                "print(f\"Val samples: {len(val_dataset)}\")\n",
                "print(f\"Test samples: {len(test_dataset)}\")\n",
                "\n",
                "# Create DataLoaders\n",
                "BATCH_SIZE = 64\n",
                "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Display a grid of 16 random training images (2 per class)\n",
                "# Iterate through the dataset or loader to collect 2 examples per class\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "# ... implementation here ...\n",
                "plt.suptitle(\"BloodMNIST Examples\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Plot the class distribution (bar chart) for the training set\n",
                "# Count occurrences of each class index in train_dataset.labels\n",
                "\n",
                "# ... implementation here ...\n",
                "plt.title(\"Class Distribution (Training Set)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Is the dataset balanced? \n",
                "\n",
                "*TODO: Write your answer here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4.2: Build and Train an MLP (5 points)\n",
                "\n",
                "Architecture:\n",
                "*   Input: 2352 (flattened 28x28x3)\n",
                "*   Hidden 1: 256 (ReLU)\n",
                "*   Hidden 2: 128 (ReLU)\n",
                "*   Output: 8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BloodMLP(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(BloodMLP, self).__init__()\n",
                "        # TODO: Define layers\n",
                "        # self.flatten = ...\n",
                "        # self.fc1 = ...\n",
                "        # self.relu = ...\n",
                "        # self.fc2 = ...\n",
                "        # self.fc3 = ...\n",
                "        pass\n",
                "\n",
                "    def forward(self, x):\n",
                "        # TODO: Implement forward pass\n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Initialize model, optimizer (Adam, lr=1e-3), and loss function (CrossEntropy)\n",
                "model = BloodMLP().to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "criterion = nn.CrossEntropyLoss()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Training Loop\n",
                "num_epochs = 30\n",
                "train_losses, val_losses = [], []\n",
                "train_accs, val_accs = [], []\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    # Training\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for images, labels in train_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        labels = labels.squeeze().long() # MedMNIST labels are (N, 1)\n",
                "        \n",
                "        # Zero gradients, forward, backward, optimize\n",
                "        # ...\n",
                "        pass\n",
                "\n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    val_correct = 0\n",
                "    val_total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in val_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            labels = labels.squeeze().long()\n",
                "            # ...\n",
                "            pass\n",
                "    \n",
                "    # Print stats\n",
                "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {running_loss:.4f} Acc: {correct/total:.4f} | Val Loss: {val_loss:.4f} Acc: {val_correct/val_total:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Plot Training Loss vs Validation Loss\n",
                "# TODO: Plot Training Acc vs Validation Acc"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4.3: Evaluation and Analysis (5 points)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Evaluate on Test Set\n",
                "model.eval()\n",
                "all_preds = []\n",
                "all_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for images, labels in test_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        outputs = model(images)\n",
                "        preds = torch.argmax(outputs, dim=1)\n",
                "        \n",
                "        all_preds.extend(preds.cpu().numpy())\n",
                "        all_labels.extend(labels.cpu().numpy().flatten())\n",
                "\n",
                "# 1. Accuracy\n",
                "# ...\n",
                "\n",
                "# 2. Confusion Matrix\n",
                "# cm = confusion_matrix(all_labels, all_preds)\n",
                "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels.values())\n",
                "# disp.plot(xticks_rotation='vertical')\n",
                "\n",
                "# 3. Classification Report\n",
                "# print(classification_report(...))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Identify 2 most confused pairs\n",
                "# TODO: Find class with lowest recall"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Display 5 misclassified examples of the lowest-recall class\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4.4: Prediction Confidence Analysis (3 points)\n",
                "\n",
                "Categorize predictions into:\n",
                "*   Confident & Correct (> 0.9)\n",
                "*   Confident & Incorrect (> 0.9)\n",
                "*   Uncertain & Correct (< 0.6)\n",
                "*   Uncertain & Incorrect (< 0.6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Find and display 2 examples from each quadrant\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Analysis:** What visual characteristics distinguish the \"Incorrect but Confident\" examples? Why might the model be overconfident?\n",
                "\n",
                "*TODO: Write your analysis here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "# Problem 5: Weight Initialization and Training Dynamics (15 points)\n",
                "\n",
                "### Q5.1: Implement Initialization Schemes (3 points)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def initialize_weights(shape, method):\n",
                "    \"\"\"\n",
                "    Args:\n",
                "        shape: tuple of (fan_in, fan_out)\n",
                "        method: 'zero', 'small_random', 'xavier', 'he'\n",
                "    Returns:\n",
                "        torch.Tensor of initialized weights\n",
                "    \"\"\"\n",
                "    fan_in, fan_out = shape\n",
                "    \n",
                "    if method == 'zero':\n",
                "        pass\n",
                "    elif method == 'small_random':\n",
                "        pass # N(0, 0.01^2)\n",
                "    elif method == 'xavier':\n",
                "        pass # N(0, 2/(fan_in + fan_out))\n",
                "    elif method == 'he':\n",
                "        pass # N(0, 2/fan_in)\n",
                "    else:\n",
                "        raise ValueError(\"Unknown method\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5.2: Activation Statistics Before Training (5 points)\n",
                "\n",
                "Architecture: 784 -> 256 -> 256 -> 256 -> 256 -> 256 -> 10\n",
                "Activations: Tanh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Define a custom MLP class that lets you inspect forward passes\n",
                "class InitMLP(nn.Module):\n",
                "    def __init__(self, init_method, activation='tanh'):\n",
                "        super().__init__()\n",
                "        # ...\n",
                "\n",
                "# TODO: Collect stats (mean/std) for each layer across the 4 init methods\n",
                "# Loop through init_methods = ['zero', 'small_random', 'xavier', 'he']\n",
                "#   Instantiate model\n",
                "#   Pass one batch of MNIST data\n",
                "#   Record layer outputs (hooks or manual forward)\n",
                "#   Note: Use the MNIST data downloaded in the 'Data Setup' section: \n",
                "#         loader = DataLoader(mnist_train, batch_size=256, shuffle=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Plot Mean Activation vs Depth (subplot 1)\n",
                "# TODO: Plot Std Activation vs Depth (subplot 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Analysis:** Which methods show vanishing/exploding gradients?\n",
                "\n",
                "*TODO: Write your analysis here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5.3: Training Dynamics Comparison (4 points)\n",
                "\n",
                "Train 4 networks (one per init) for 10 epochs on MNIST."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Training loop for the 4 models\n",
                "# Plot all 4 training loss curves\n",
                "# Report final test accuracy\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5.4: ReLU Activation Experiment (3 points)\n",
                "\n",
                "Repeat Q5.2 and Q5.3 with **ReLU** instead of Tanh."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Activation statistics with ReLU\n",
                "# TODO: Training comparison with ReLU\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Analysis:** Compare Tanh vs ReLU dynamics and best initialization methods.\n",
                "\n",
                "*TODO: Write your analysis here.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "# Problem 6: Building a Neural Network Library (25 points)\n",
                "\n",
                "You will implement `mytorch` in the provided auxiliary files and then use it here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add current directory to path so we can import mytorch\n",
                "import sys\n",
                "import os\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "import mytorch.nn as nn\n",
                "import mytorch.utils as utils"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6.1 - Q6.5: Implementation\n",
                "\n",
                "Please implement the classes in:\n",
                "1.  `mytorch/nn/modules/linear.py`\n",
                "2.  `mytorch/nn/modules/activation.py`\n",
                "3.  `mytorch/nn/modules/loss.py`\n",
                "4.  `mytorch/nn/sequential.py`\n",
                "5.  `mytorch/nn/optim.py`\n",
                "\n",
                "*(Editor's note: You should edit these files directly.)*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6.6: Gradient Checking (3 points)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mytorch.utils import gradient_check\n",
                "\n",
                "# Create a small dummy network for checking\n",
                "input_size = 5\n",
                "hidden_size = 10\n",
                "output_size = 3\n",
                "batch_size = 4\n",
                "\n",
                "model = nn.Sequential(\n",
                "    nn.Linear(input_size, hidden_size),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(hidden_size, output_size)\n",
                ")\n",
                "\n",
                "loss_fn = nn.SoftmaxCrossEntropy()\n",
                "\n",
                "# Random data\n",
                "x_dummy = np.random.randn(batch_size, input_size)\n",
                "y_dummy = np.eye(output_size)[np.random.choice(output_size, batch_size)]\n",
                "\n",
                "# Check gradients\n",
                "try:\n",
                "    error = gradient_check(model, loss_fn, x_dummy, y_dummy)\n",
                "    print(f\"Gradient check Max Relative Error: {error:.2e}\")\n",
                "    if error < 1e-5:\n",
                "        print(\"Gradient check PASSED!\")\n",
                "    else:\n",
                "        print(\"Gradient check FAILED!\")\n",
                "except NotImplementedError:\n",
                "    print(\"Gradient check not implemented yet.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6.7: Train and Evaluate on MNIST (4 points)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Train on MNIST using mytorch\n",
                "# 1. Load MNIST (flattened to 784)\n",
                "#    Note: Use the MNIST data downloaded in the 'Data Setup' section.\n",
                "#    You can access it via torchvision or just load the tensors if already loaded.\n",
                "#    X_train = mnist_train.data.float().view(-1, 784) / 255.0\n",
                "#    y_train = mnist_train.targets\n",
                "\n",
                "# 2. Create model: 784 -> 128 (ReLU) -> 64 (ReLU) -> 10\n",
                "# 3. Optimizer: SGD(lr=0.1)\n",
                "# 4. Loss: SoftmaxCrossEntropy\n",
                "# 5. Train for 3 epochs\n",
                "\n",
                "# Plot loss\n",
                "# Report test accuracy\n",
                "# Display 10 random test predictions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}